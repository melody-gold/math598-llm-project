{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b372e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from dataclasses import dataclass \n",
    "import requests\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from jaxtyping import Float, Int\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from typing import List\n",
    "\n",
    "import unicodedata\n",
    "import json\n",
    "from collections import Counter, defaultdict\n",
    "import base64\n",
    "from IPython.display import Image, display\n",
    "\n",
    "\n",
    "@dataclass \n",
    "class Config:\n",
    "    d_model : int \n",
    "    d_vocab : int\n",
    "    d_hidden : int\n",
    "    #no n_context \n",
    "\n",
    "# guttenburg dataset code in existing notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6c76b0",
   "metadata": {},
   "source": [
    "## Getting Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dccfcc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Getting book 84...\n",
      "\t419422 characters read\n",
      "Getting book 15...\n",
      "\t1238469 characters read\n",
      "Getting book 18...\n",
      "\t1172825 characters read\n",
      "Getting book 82...\n",
      "\t1103796 characters read\n",
      "Getting book 996...\n",
      "\t2299352 characters read\n",
      "Getting book 2600...\n",
      "\t3208337 characters read\n"
     ]
    }
   ],
   "source": [
    "def get_gutenberg_book(\n",
    "\tid: int|None = 84,\n",
    "\tdata_temp: Path|str = \"../data/gutenberg_data\",\n",
    "\tremove_gutenberg_meta: bool = True,\n",
    ") -> str:\n",
    "\t\n",
    "\tdata_temp = Path(data_temp)\n",
    "\tdata_temp.mkdir(parents=True, exist_ok=True)\n",
    "\t\n",
    "\turl: str = f\"https://www.gutenberg.org/cache/epub/{id}/pg{id}.txt\"\n",
    "\tdata_path: Path = Path(data_temp) / f\"{id}.txt\"\n",
    "\tdata: str\n",
    "\t# read from cache if it exists\n",
    "\tif data_path.exists():\n",
    "\t\twith open(data_path, 'r', encoding='utf-8') as file:\n",
    "\t\t\tdata = file.read()\n",
    "\telse:\n",
    "\t\t# download if it doesn't exist\n",
    "\t\tresponse = requests.get(url)\n",
    "\t\tresponse.raise_for_status()  # Ensure that the download was successful\n",
    "\t\tdata = response.text\n",
    "\n",
    "\t\t# save to cache\n",
    "\t\twith open(data_path, 'w', encoding='utf-8') as file:\n",
    "\t\t\tfile.write(data)\n",
    "\n",
    "\t# remove header/footer\n",
    "\tif remove_gutenberg_meta:\n",
    "\t\tdata = '***'.join(data.split('***')[2:])\n",
    "\t\tdata = '***'.join(data.split('***')[:-1])\n",
    "\t\n",
    "\treturn data\n",
    "\n",
    "def get_many_books(\n",
    "\t\tids: list[int],\n",
    "\t\tdata_temp: Path|str = \"../data/gutenberg_data\",\n",
    "\t) -> list[str]:\n",
    "\t\n",
    "\tdata: list[str] = []\n",
    "\tfor id in ids:\n",
    "\t\tprint(f\"Getting book {id}...\")\n",
    "\t\titem: str = get_gutenberg_book(id, data_temp)\n",
    "\t\tprint(f\"\\t{len(item)} characters read\")\n",
    "\t\tdata.append(item)\n",
    "\t\n",
    "\treturn data\n",
    "\n",
    "DATA_RAW: list[str] = get_many_books([84, 15, 18, 82, 996, 2600])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76b953f1",
   "metadata": {},
   "source": [
    "$$A(\\mathbf{X}) = \\sigma (\\mathbf{X} \\; \\mathbf{W}_{QK} \\; \\mathbf{X}^\\text{T} + \\mathbf{M})$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d59db994",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Axes should be separated with spaces, not commas",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------",
      "ValueError                                Traceback (most recent call last)",
      "Cell In[7], line 1\n----> 1 class MLP(nn.Module):\n      2     def __init__(self, config: Config): # matrices to initialize\n      3         super().__init__()\n",
      "Cell In[7], line 7, in MLP()\n      4     self.linear_up: nn.Linear = nn.Linear(config.d_model, config.d_hidden)\n      5     self.linear_down: nn.Linear = nn.Linear(config.d_hidden, config.d_model)\n----> 7 def forward(self, x: Float[torch.Tensor, \"*, d_model\"]) -> Float[torch.Tensor, \"*, d_model\"]:\n      8     x = self.linear_up(x)\n      9     x = torch.relu(x)\n",
      "File ~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Mines/MATH598/decoding-gpt/.venv/lib/python3.11/site-packages/jaxtyping/_array_types.py:669, in _MetaAbstractDtype.__getitem__(***failed resolving arguments***)\n    667         out = Union[out]\n    668 else:\n--> 669     out = _make_array(array_type, dim_str, cls.dtypes, cls.__name__)\n    670     if out is _not_made:\n    671         raise ValueError(\"Invalid jaxtyping type annotation.\")\n",
      "File ~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Mines/MATH598/decoding-gpt/.venv/lib/python3.11/site-packages/jaxtyping/_array_types.py:599, in _make_array(*args, **kwargs)\n    598 def _make_array(*args, **kwargs):\n--> 599     out = _make_array_cached(*args, **kwargs)\n    601     if type(out) is tuple:\n    602         array_type, name, dtypes, dims, index_variadic, dim_str = out\n",
      "File ~/Library/Mobile Documents/com~apple~CloudDocs/Documents/Mines/MATH598/decoding-gpt/.venv/lib/python3.11/site-packages/jaxtyping/_array_types.py:389, in _make_array_cached(array_type, dim_str, dtypes, name)\n    384 for index, elem in enumerate(dim_str.split()):\n    385     if \",\" in elem and \"(\" not in elem:\n    386         # Common mistake.\n    387         # Disable in the case that there's brackets to allow for function calls,\n    388         # e.g. `min(foo,bar)`, in symbolic axes.\n--> 389         raise ValueError(\"Axes should be separated with spaces, not commas\")\n    390     if elem.endswith(\"#\"):\n    391         raise ValueError(\n    392             \"As of jaxtyping v0.1.0, broadcastable axes are now denoted \"\n    393             \"with a # at the start, rather than at the end\"\n    394         )\n",
      "ValueError: Axes should be separated with spaces, not commas"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, config: Config): # matrices to initialize\n",
    "        super().__init__()\n",
    "        self.linear_up: nn.Linear = nn.Linear(config.d_model, config.d_hidden)\n",
    "        self.linear_down: nn.Linear = nn.Linear(config.d_hidden, config.d_model)\n",
    "    \n",
    "    def forward(self, x: Float[torch.Tensor, \"*, d_model\"]) -> Float[torch.Tensor, \"*, d_model\"]:\n",
    "        x = self.linear_up(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear_down(x)\n",
    "        return x\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.token_embedding = nn.Embedding(config.d_vocab, config.d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37000370",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nn' is not defined",
     "output_type": "error",
     "traceback": [
      "---------------------------------------------------------------------------",
      "NameError                                 Traceback (most recent call last)",
      "Cell In[3], line 1\n----> 1 class TransformerBlock(nn.Module):\n      2     def __init__(self, config: Config):\n      3         super().__init__()\n",
      "NameError: name 'nn' is not defined"
     ]
    }
   ],
   "source": [
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.token_embedding = nn.Embedding(config.d_vocab, config.d_model)\n",
    "    \n",
    "    # mlp and attention head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aa29c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class transformer(nn.Module):\n",
    "    def __init__(self, config: Config):\n",
    "        super().__init__()\n",
    "        self.config = config\n",
    "        self.token_embedding = nn.Embedding(config.d_vocab, config.d_model)\n",
    "        \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decoding-gpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
